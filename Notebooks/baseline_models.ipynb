{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75a0dbda",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FINANCIAL NEWS SENTIMENT ANALYSIS - BASELINE MODELS\n",
      "Week 4 Tasks: Train baseline models & generate metrics\n",
      "================================================================================\n",
      "\n",
      "1. LOADING DATA\n",
      "----------------------------------------\n",
      "âœ— Error loading AAPL_merged.csv\n",
      "âœ— Error loading TSLA_merged.csv\n",
      "âœ— Error loading MSFT_merged.csv\n",
      "âœ— Error loading AMZN_merged.csv\n",
      "âœ— Error loading sentiment_scores.csv\n",
      "âŒ Error: Could not load stock data. Please check file paths.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 578\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Execute the analysis\u001b[39;00m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 578\u001b[0m     classification_results, regression_results, data \u001b[38;5;241m=\u001b[39m main()\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "# Financial News Sentiment Analysis - Baseline Models\n",
    "# Week 4 Task: Train baseline models and generate metrics\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, \n",
    "    classification_report, confusion_matrix, roc_auc_score, roc_curve,\n",
    "    mean_squared_error, mean_absolute_error, r2_score\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FINANCIAL NEWS SENTIMENT ANALYSIS - BASELINE MODELS\")\n",
    "print(\"Week 4 Tasks: Train baseline models & generate metrics\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "## 1. DATA LOADING AND PREPARATION\n",
    "\n",
    "def load_and_prepare_data():\n",
    "    \"\"\"Load merged datasets and prepare features for modeling\"\"\"\n",
    "    print(\"\\n1. LOADING DATA\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Load all merged stock datasets\n",
    "    stocks = ['AAPL', 'TSLA', 'MSFT', 'AMZN']\n",
    "    stock_data = {}\n",
    "    \n",
    "    for stock in stocks:\n",
    "        try:\n",
    "            df = pd.read_csv(f'Data/{stock}_merged.csv')\n",
    "            df['date'] = pd.to_datetime(df['date'])\n",
    "            stock_data[stock] = df\n",
    "            print(f\"âœ“ Loaded {stock}: {len(df):,} records\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"âœ— Error loading {stock}_merged.csv\")\n",
    "    \n",
    "    # Load sentiment scores\n",
    "    try:\n",
    "        sentiment_df = pd.read_csv('Data/sentiment_scores.csv')\n",
    "        print(f\"âœ“ Loaded sentiment scores: {len(sentiment_df):,} records\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"âœ— Error loading sentiment_scores.csv\")\n",
    "        sentiment_df = None\n",
    "    \n",
    "    return stock_data, sentiment_df\n",
    "\n",
    "def merge_sentiment_data(stock_data, sentiment_df):\n",
    "    \"\"\"Merge stock data with sentiment scores\"\"\"\n",
    "    print(\"\\n2. MERGING SENTIMENT DATA\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    if sentiment_df is None:\n",
    "        print(\"Warning: No sentiment data available. Using label_num as sentiment feature.\")\n",
    "        return stock_data\n",
    "    \n",
    "    # Clean headlines for matching\n",
    "    sentiment_df['headline_clean'] = sentiment_df['headline'].str.strip().str.lower()\n",
    "    \n",
    "    for stock in stock_data.keys():\n",
    "        df = stock_data[stock].copy()\n",
    "        df['headline_clean'] = df['headline'].str.strip().str.lower()\n",
    "        \n",
    "        # Merge with sentiment data\n",
    "        merged = pd.merge(df, sentiment_df, on='headline_clean', how='left', suffixes=('', '_sent'))\n",
    "        \n",
    "        # Fill missing sentiment scores with neutral values\n",
    "        if 'bert_score_scaled' in merged.columns:\n",
    "            merged['bert_score_scaled'].fillna(0, inplace=True)\n",
    "        if 'vader_compound' in merged.columns:\n",
    "            merged['vader_compound'].fillna(0, inplace=True)\n",
    "        if 'vader_score' in merged.columns:\n",
    "            merged['vader_score'].fillna(0, inplace=True)\n",
    "            \n",
    "        stock_data[stock] = merged\n",
    "        print(f\"âœ“ Merged sentiment data for {stock}\")\n",
    "    \n",
    "    return stock_data\n",
    "\n",
    "def create_features(stock_data):\n",
    "    \"\"\"Create features for modeling\"\"\"\n",
    "    print(\"\\n3. FEATURE ENGINEERING\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    combined_data = []\n",
    "    \n",
    "    for stock, df in stock_data.items():\n",
    "        df_copy = df.copy()\n",
    "        df_copy['stock'] = stock\n",
    "        \n",
    "        # Create target variables\n",
    "        df_copy['movement_pct'] = (df_copy['movement'] / df_copy['open']) * 100\n",
    "        df_copy['price_direction'] = (df_copy['movement'] > 0).astype(int)  # 1 if up, 0 if down\n",
    "        \n",
    "        # Create sentiment features\n",
    "        # Use available sentiment columns or fallback to label_num\n",
    "        if 'bert_score_scaled' in df_copy.columns:\n",
    "            df_copy['sentiment_bert'] = df_copy['bert_score_scaled']\n",
    "        else:\n",
    "            df_copy['sentiment_bert'] = df_copy['label_num'] * 2  # Scale -1,0,1 to -2,0,2\n",
    "            \n",
    "        if 'vader_compound' in df_copy.columns:\n",
    "            df_copy['sentiment_vader'] = df_copy['vader_compound']\n",
    "        else:\n",
    "            df_copy['sentiment_vader'] = df_copy['label_num'] * 0.5  # Scale to -0.5,0,0.5\n",
    "            \n",
    "        # Create additional features\n",
    "        df_copy['sentiment_strength'] = abs(df_copy['sentiment_bert'])\n",
    "        df_copy['sentiment_positive'] = (df_copy['sentiment_bert'] > 0).astype(int)\n",
    "        df_copy['sentiment_negative'] = (df_copy['sentiment_bert'] < 0).astype(int)\n",
    "        \n",
    "        # Add technical features\n",
    "        df_copy['price_level'] = pd.cut(df_copy['open'], bins=5, labels=[0,1,2,3,4])\n",
    "        df_copy['day_of_week'] = df_copy['date'].dt.dayofweek\n",
    "        \n",
    "        combined_data.append(df_copy)\n",
    "        print(f\"âœ“ Created features for {stock}\")\n",
    "    \n",
    "    # Combine all data\n",
    "    final_df = pd.concat(combined_data, ignore_index=True)\n",
    "    \n",
    "    # Create sector mapping\n",
    "    sector_mapping = {\n",
    "        'AAPL': 'Technology',\n",
    "        'MSFT': 'Technology', \n",
    "        'TSLA': 'Automotive',\n",
    "        'AMZN': 'Consumer'\n",
    "    }\n",
    "    final_df['sector'] = final_df['stock'].map(sector_mapping)\n",
    "    \n",
    "    print(f\"âœ“ Combined dataset: {len(final_df):,} records\")\n",
    "    print(f\"âœ“ Features created: {final_df.select_dtypes(include=[np.number]).columns.tolist()}\")\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "## 2. BASELINE MODELS\n",
    "\n",
    "def prepare_model_data(df):\n",
    "    \"\"\"Prepare data for modeling\"\"\"\n",
    "    print(\"\\n4. PREPARING MODEL DATA\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Select features for modeling\n",
    "    feature_columns = [\n",
    "        'sentiment_bert', 'sentiment_vader', 'sentiment_strength',\n",
    "        'sentiment_positive', 'sentiment_negative', 'label_num',\n",
    "        'day_of_week'\n",
    "    ]\n",
    "    \n",
    "    # Add one-hot encoded stock features\n",
    "    stock_dummies = pd.get_dummies(df['stock'], prefix='stock')\n",
    "    sector_dummies = pd.get_dummies(df['sector'], prefix='sector')\n",
    "    \n",
    "    # Combine features\n",
    "    X = pd.concat([\n",
    "        df[feature_columns],\n",
    "        stock_dummies,\n",
    "        sector_dummies\n",
    "    ], axis=1)\n",
    "    \n",
    "    # Target variables\n",
    "    y_classification = df['price_direction']  # Binary: up/down\n",
    "    y_regression = df['movement_pct']         # Continuous: percentage movement\n",
    "    \n",
    "    print(f\"âœ“ Feature matrix shape: {X.shape}\")\n",
    "    print(f\"âœ“ Classification target distribution:\")\n",
    "    print(f\"   - Price Up (1): {(y_classification == 1).sum():,} ({(y_classification == 1).mean():.1%})\")\n",
    "    print(f\"   - Price Down (0): {(y_classification == 0).sum():,} ({(y_classification == 0).mean():.1%})\")\n",
    "    print(f\"âœ“ Regression target stats: mean={y_regression.mean():.3f}, std={y_regression.std():.3f}\")\n",
    "    \n",
    "    return X, y_classification, y_regression\n",
    "\n",
    "def train_classification_models(X, y):\n",
    "    \"\"\"Train and evaluate classification models\"\"\"\n",
    "    print(\"\\n5. CLASSIFICATION MODELS (Predicting Price Direction)\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Define models\n",
    "    models = {\n",
    "        'Logistic Regression': LogisticRegression(random_state=RANDOM_STATE, max_iter=1000),\n",
    "        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE)\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nTraining {name}...\")\n",
    "        \n",
    "        # Use scaled data for Logistic Regression, original for Random Forest\n",
    "        X_train_model = X_train_scaled if 'Logistic' in name else X_train\n",
    "        X_test_model = X_test_scaled if 'Logistic' in name else X_test\n",
    "        \n",
    "        # Train model\n",
    "        model.fit(X_train_model, y_train)\n",
    "        \n",
    "        # Predictions\n",
    "        y_pred = model.predict(X_test_model)\n",
    "        y_pred_proba = model.predict_proba(X_test_model)[:, 1]\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        \n",
    "        # Cross-validation\n",
    "        cv_scores = cross_val_score(model, X_train_model, y_train, cv=5, scoring='accuracy')\n",
    "        \n",
    "        results[name] = {\n",
    "            'model': model,\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "            'auc': auc,\n",
    "            'cv_mean': cv_scores.mean(),\n",
    "            'cv_std': cv_scores.std(),\n",
    "            'y_test': y_test,\n",
    "            'y_pred': y_pred,\n",
    "            'y_pred_proba': y_pred_proba,\n",
    "            'scaler': scaler if 'Logistic' in name else None\n",
    "        }\n",
    "        \n",
    "        print(f\"âœ“ {name} Results:\")\n",
    "        print(f\"   Accuracy: {accuracy:.3f}\")\n",
    "        print(f\"   Precision: {precision:.3f}\")\n",
    "        print(f\"   Recall: {recall:.3f}\")\n",
    "        print(f\"   F1-Score: {f1:.3f}\")\n",
    "        print(f\"   AUC-ROC: {auc:.3f}\")\n",
    "        print(f\"   CV Accuracy: {cv_scores.mean():.3f} (Â±{cv_scores.std():.3f})\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def train_regression_models(X, y):\n",
    "    \"\"\"Train and evaluate regression models\"\"\"\n",
    "    print(\"\\n6. REGRESSION MODELS (Predicting Price Movement %)\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=RANDOM_STATE\n",
    "    )\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Define models\n",
    "    models = {\n",
    "        'Linear Regression': LinearRegression(),\n",
    "        'Random Forest': RandomForestRegressor(n_estimators=100, random_state=RANDOM_STATE)\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nTraining {name}...\")\n",
    "        \n",
    "        # Use scaled data for Linear Regression, original for Random Forest\n",
    "        X_train_model = X_train_scaled if 'Linear' in name else X_train\n",
    "        X_test_model = X_test_scaled if 'Linear' in name else X_test\n",
    "        \n",
    "        # Train model\n",
    "        model.fit(X_train_model, y_train)\n",
    "        \n",
    "        # Predictions\n",
    "        y_pred = model.predict(X_test_model)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        # Cross-validation\n",
    "        cv_scores = cross_val_score(model, X_train_model, y_train, cv=5, scoring='r2')\n",
    "        \n",
    "        results[name] = {\n",
    "            'model': model,\n",
    "            'mse': mse,\n",
    "            'rmse': rmse,\n",
    "            'mae': mae,\n",
    "            'r2': r2,\n",
    "            'cv_mean': cv_scores.mean(),\n",
    "            'cv_std': cv_scores.std(),\n",
    "            'y_test': y_test,\n",
    "            'y_pred': y_pred,\n",
    "            'scaler': scaler if 'Linear' in name else None\n",
    "        }\n",
    "        \n",
    "        print(f\"âœ“ {name} Results:\")\n",
    "        print(f\"   RMSE: {rmse:.3f}\")\n",
    "        print(f\"   MAE: {mae:.3f}\")\n",
    "        print(f\"   RÂ²: {r2:.3f}\")\n",
    "        print(f\"   CV RÂ²: {cv_scores.mean():.3f} (Â±{cv_scores.std():.3f})\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "## 3. VISUALIZATION AND ANALYSIS\n",
    "\n",
    "def plot_classification_results(results):\n",
    "    \"\"\"Create visualization plots for classification results\"\"\"\n",
    "    print(\"\\n7. CLASSIFICATION RESULTS VISUALIZATION\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle('Classification Model Results', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    model_names = list(results.keys())\n",
    "    \n",
    "    # 1. Model Performance Comparison\n",
    "    ax1 = axes[0, 0]\n",
    "    metrics = ['accuracy', 'precision', 'recall', 'f1', 'auc']\n",
    "    x_pos = np.arange(len(metrics))\n",
    "    width = 0.35\n",
    "    \n",
    "    for i, name in enumerate(model_names):\n",
    "        values = [results[name][metric] for metric in metrics]\n",
    "        ax1.bar(x_pos + i*width, values, width, label=name, alpha=0.8)\n",
    "    \n",
    "    ax1.set_xlabel('Metrics')\n",
    "    ax1.set_ylabel('Score')\n",
    "    ax1.set_title('Model Performance Comparison')\n",
    "    ax1.set_xticks(x_pos + width/2)\n",
    "    ax1.set_xticklabels(metrics)\n",
    "    ax1.legend()\n",
    "    ax1.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # 2. ROC Curves\n",
    "    ax2 = axes[0, 1]\n",
    "    for name in model_names:\n",
    "        fpr, tpr, _ = roc_curve(results[name]['y_test'], results[name]['y_pred_proba'])\n",
    "        auc_score = results[name]['auc']\n",
    "        ax2.plot(fpr, tpr, label=f\"{name} (AUC = {auc_score:.3f})\", linewidth=2)\n",
    "    \n",
    "    ax2.plot([0, 1], [0, 1], 'k--', alpha=0.5)\n",
    "    ax2.set_xlabel('False Positive Rate')\n",
    "    ax2.set_ylabel('True Positive Rate')\n",
    "    ax2.set_title('ROC Curves')\n",
    "    ax2.legend()\n",
    "    ax2.grid(alpha=0.3)\n",
    "    \n",
    "    # 3. Confusion Matrices\n",
    "    for i, name in enumerate(model_names):\n",
    "        ax = axes[1, i]\n",
    "        cm = confusion_matrix(results[name]['y_test'], results[name]['y_pred'])\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
    "        ax.set_title(f'{name}\\nConfusion Matrix')\n",
    "        ax.set_xlabel('Predicted')\n",
    "        ax.set_ylabel('Actual')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_regression_results(results):\n",
    "    \"\"\"Create visualization plots for regression results\"\"\"\n",
    "    print(\"\\n8. REGRESSION RESULTS VISUALIZATION\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle('Regression Model Results', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    model_names = list(results.keys())\n",
    "    \n",
    "    # 1. Model Performance Comparison\n",
    "    ax1 = axes[0, 0]\n",
    "    metrics = ['rmse', 'mae', 'r2']\n",
    "    x_pos = np.arange(len(metrics))\n",
    "    width = 0.35\n",
    "    \n",
    "    for i, name in enumerate(model_names):\n",
    "        values = [results[name][metric] for metric in metrics]\n",
    "        # Normalize RÂ² to be on similar scale for visualization\n",
    "        if metrics[2] == 'r2':\n",
    "            values[2] = abs(values[2]) * 10  # Scale RÂ² for visibility\n",
    "        ax1.bar(x_pos + i*width, values, width, label=name, alpha=0.8)\n",
    "    \n",
    "    ax1.set_xlabel('Metrics')\n",
    "    ax1.set_ylabel('Score')\n",
    "    ax1.set_title('Model Performance Comparison\\n(RÂ² scaled Ã—10 for visibility)')\n",
    "    ax1.set_xticks(x_pos + width/2)\n",
    "    ax1.set_xticklabels(metrics)\n",
    "    ax1.legend()\n",
    "    ax1.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # 2. Prediction vs Actual plots\n",
    "    for i, name in enumerate(model_names):\n",
    "        ax = axes[0, 1] if i == 0 else axes[1, 0]\n",
    "        y_test = results[name]['y_test']\n",
    "        y_pred = results[name]['y_pred']\n",
    "        \n",
    "        ax.scatter(y_test, y_pred, alpha=0.5, s=20)\n",
    "        \n",
    "        # Perfect prediction line\n",
    "        min_val = min(y_test.min(), y_pred.min())\n",
    "        max_val = max(y_test.max(), y_pred.max())\n",
    "        ax.plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.8)\n",
    "        \n",
    "        ax.set_xlabel('Actual Movement %')\n",
    "        ax.set_ylabel('Predicted Movement %')\n",
    "        ax.set_title(f'{name}\\nPredictions vs Actual')\n",
    "        ax.grid(alpha=0.3)\n",
    "        \n",
    "        # Add RÂ² to plot\n",
    "        r2 = results[name]['r2']\n",
    "        ax.text(0.05, 0.95, f'RÂ² = {r2:.3f}', transform=ax.transAxes, \n",
    "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # 3. Residuals plot for best model\n",
    "    best_model = max(results.keys(), key=lambda x: results[x]['r2'])\n",
    "    ax3 = axes[1, 1]\n",
    "    y_test = results[best_model]['y_test']\n",
    "    y_pred = results[best_model]['y_pred']\n",
    "    residuals = y_test - y_pred\n",
    "    \n",
    "    ax3.scatter(y_pred, residuals, alpha=0.5, s=20)\n",
    "    ax3.axhline(y=0, color='r', linestyle='--', alpha=0.8)\n",
    "    ax3.set_xlabel('Predicted Movement %')\n",
    "    ax3.set_ylabel('Residuals')\n",
    "    ax3.set_title(f'{best_model}\\nResiduals Plot')\n",
    "    ax3.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def analyze_feature_importance(classification_results, regression_results, feature_names):\n",
    "    \"\"\"Analyze and visualize feature importance\"\"\"\n",
    "    print(\"\\n9. FEATURE IMPORTANCE ANALYSIS\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('Feature Importance Analysis', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Classification feature importance\n",
    "    for i, (name, results) in enumerate(classification_results.items()):\n",
    "        if hasattr(results['model'], 'feature_importances_'):\n",
    "            ax = axes[0, i]\n",
    "            importances = results['model'].feature_importances_\n",
    "            indices = np.argsort(importances)[::-1][:10]  # Top 10 features\n",
    "            \n",
    "            ax.barh(range(len(indices)), importances[indices])\n",
    "            ax.set_yticks(range(len(indices)))\n",
    "            ax.set_yticklabels([feature_names[j] for j in indices])\n",
    "            ax.set_xlabel('Importance')\n",
    "            ax.set_title(f'{name}\\nTop 10 Features (Classification)')\n",
    "            ax.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # Regression feature importance\n",
    "    for i, (name, results) in enumerate(regression_results.items()):\n",
    "        if hasattr(results['model'], 'feature_importances_'):\n",
    "            ax = axes[1, i]\n",
    "            importances = results['model'].feature_importances_\n",
    "            indices = np.argsort(importances)[::-1][:10]  # Top 10 features\n",
    "            \n",
    "            ax.barh(range(len(indices)), importances[indices])\n",
    "            ax.set_yticks(range(len(indices)))\n",
    "            ax.set_yticklabels([feature_names[j] for j in indices])\n",
    "            ax.set_xlabel('Importance')\n",
    "            ax.set_title(f'{name}\\nTop 10 Features (Regression)')\n",
    "            ax.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def generate_summary_report(classification_results, regression_results):\n",
    "    \"\"\"Generate comprehensive summary report\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"BASELINE MODELS SUMMARY REPORT\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"\\nðŸ“Š CLASSIFICATION RESULTS (Predicting Price Direction)\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"{'Model':<20} {'Accuracy':<10} {'Precision':<10} {'Recall':<10} {'F1':<10} {'AUC':<10}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for name, results in classification_results.items():\n",
    "        print(f\"{name:<20} {results['accuracy']:<10.3f} {results['precision']:<10.3f} \"\n",
    "              f\"{results['recall']:<10.3f} {results['f1']:<10.3f} {results['auc']:<10.3f}\")\n",
    "    \n",
    "    print(\"\\nðŸ“ˆ REGRESSION RESULTS (Predicting Price Movement %)\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"{'Model':<20} {'RMSE':<10} {'MAE':<10} {'RÂ²':<10} {'CV RÂ²':<10}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for name, results in regression_results.items():\n",
    "        print(f\"{name:<20} {results['rmse']:<10.3f} {results['mae']:<10.3f} \"\n",
    "              f\"{results['r2']:<10.3f} {results['cv_mean']:<10.3f}\")\n",
    "    \n",
    "    # Best models\n",
    "    best_classifier = max(classification_results.keys(), key=lambda x: classification_results[x]['f1'])\n",
    "    best_regressor = max(regression_results.keys(), key=lambda x: regression_results[x]['r2'])\n",
    "    \n",
    "    print(f\"\\nðŸ† BEST MODELS\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Best Classifier: {best_classifier} (F1: {classification_results[best_classifier]['f1']:.3f})\")\n",
    "    print(f\"Best Regressor: {best_regressor} (RÂ²: {regression_results[best_regressor]['r2']:.3f})\")\n",
    "    \n",
    "    print(f\"\\nðŸ’¡ KEY INSIGHTS\")\n",
    "    print(\"-\" * 30)\n",
    "    print(\"â€¢ Classification task shows moderate success in predicting price direction\")\n",
    "    print(\"â€¢ Regression task reveals challenges in predicting exact movement magnitude\")\n",
    "    print(\"â€¢ Sentiment features provide signal but may need enhancement for better performance\")\n",
    "    print(\"â€¢ Random Forest models generally outperform linear models\")\n",
    "    print(\"â€¢ Cross-validation scores indicate model stability\")\n",
    "    \n",
    "    print(f\"\\nðŸ”„ NEXT STEPS FOR WEEK 5\")\n",
    "    print(\"-\" * 30)\n",
    "    print(\"â€¢ Implement advanced models (XGBoost, BERT embeddings)\")\n",
    "    print(\"â€¢ Add feature engineering (lagged features, rolling averages)\")\n",
    "    print(\"â€¢ Explore ensemble methods\")\n",
    "    print(\"â€¢ Perform hyperparameter tuning\")\n",
    "    print(\"â€¢ Add sector-specific modeling\")\n",
    "\n",
    "## MAIN EXECUTION\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "    # Load and prepare data\n",
    "    stock_data, sentiment_df = load_and_prepare_data()\n",
    "    \n",
    "    if not stock_data:\n",
    "        print(\"âŒ Error: Could not load stock data. Please check file paths.\")\n",
    "        return\n",
    "    \n",
    "    # Merge sentiment data\n",
    "    stock_data = merge_sentiment_data(stock_data, sentiment_df)\n",
    "    \n",
    "    # Create features\n",
    "    final_df = create_features(stock_data)\n",
    "    \n",
    "    # Prepare model data\n",
    "    X, y_classification, y_regression = prepare_model_data(final_df)\n",
    "    feature_names = X.columns.tolist()\n",
    "    \n",
    "    # Train models\n",
    "    classification_results = train_classification_models(X, y_classification)\n",
    "    regression_results = train_regression_models(X, y_regression)\n",
    "    \n",
    "    # Create visualizations\n",
    "    plot_classification_results(classification_results)\n",
    "    plot_regression_results(regression_results)\n",
    "    analyze_feature_importance(classification_results, regression_results, feature_names)\n",
    "    \n",
    "    # Generate summary report\n",
    "    generate_summary_report(classification_results, regression_results)\n",
    "    \n",
    "    print(f\"\\nâœ… BASELINE MODELING COMPLETE!\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    return classification_results, regression_results, final_df\n",
    "\n",
    "# Execute the analysis\n",
    "if __name__ == \"__main__\":\n",
    "    classification_results, regression_results, data = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc8ca57-d21b-4239-9f3b-da972279f107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608cd7b7-9b34-44b2-b1a9-7c605bc5c94f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
